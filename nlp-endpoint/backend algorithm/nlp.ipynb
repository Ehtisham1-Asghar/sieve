{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWYu_6CRqKZo",
        "outputId": "af5dcb5f-1d12-4013-94d9-4d38713fc1d8"
      },
      "source": [
        "!pip install textract"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textract in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "Requirement already satisfied: python-pptx==0.6.18 in /usr/local/lib/python3.7/dist-packages (from textract) (0.6.18)\n",
            "Requirement already satisfied: pdfminer.six==20181108 in /usr/local/lib/python3.7/dist-packages (from textract) (20181108)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: EbookLib==0.17.1 in /usr/local/lib/python3.7/dist-packages (from textract) (0.17.1)\n",
            "Requirement already satisfied: argcomplete==1.10.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.10.0)\n",
            "Requirement already satisfied: extract-msg==0.23.1 in /usr/local/lib/python3.7/dist-packages (from textract) (0.23.1)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: SpeechRecognition==3.8.1 in /usr/local/lib/python3.7/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: docx2txt==0.8 in /usr/local/lib/python3.7/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: beautifulsoup4==4.8.0 in /usr/local/lib/python3.7/dist-packages (from textract) (4.8.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.7/dist-packages (from python-pptx==0.6.18->textract) (1.4.3)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx==0.6.18->textract) (7.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx==0.6.18->textract) (4.2.6)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20181108->textract) (2.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20181108->textract) (3.10.1)\n",
            "Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.7/dist-packages (from extract-msg==0.23.1->textract) (0.46)\n",
            "Requirement already satisfied: tzlocal==1.5.1 in /usr/local/lib/python3.7/dist-packages (from extract-msg==0.23.1->textract) (1.5.1)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.7/dist-packages (from extract-msg==0.23.1->textract) (2.1.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4==4.8.0->textract) (2.2.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5liU5oakqaB6",
        "outputId": "f87d241c-1c5e-479c-c147-e5384db6c61c"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import collections\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from itertools import chain\n",
        "import textract\n",
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "import nltk\n",
        "import collections\n",
        "import PyPDF2\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnmbLA8WrJXy"
      },
      "source": [
        "def Preprocessfile(filename):\n",
        "  text = textract.process(filename)\n",
        "  text= text.decode('utf-8').replace(\"\\\\n\", \" \")\n",
        "  # print(text)\n",
        "  x=[]\n",
        "  tokens=word_tokenize(text)\n",
        "  tok=[w.lower() for w in tokens]\n",
        "  table=str.maketrans('','',string.punctuation)\n",
        "  strpp=[w.translate(table) for w in tok]\n",
        "  words=[word for word in strpp if word.isalpha()]\n",
        "  stop_words=set(stopwords.words('english'))\n",
        "  words=[w for w in words if not w in stop_words]\n",
        "  x.append(words)\n",
        "  # print(x)\n",
        "  res=\" \".join(chain.from_iterable(x))\n",
        "  return res"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sMV-BEBsD5R",
        "outputId": "df1d5b94-92df-4d96-9947-9c84234f6623"
      },
      "source": [
        "x=Preprocessfile('jobtype.txt')\n",
        "y=Preprocessfile('resume.pdf')\n",
        "text=[y,x]\n",
        "\n",
        "\n",
        "\n",
        "#print the similarity score\n",
        "print(\"\\n Similarity Score: \")\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(text)\n",
        "print(cosine_similarity(count_matrix))\n",
        "matchpercent = cosine_similarity(count_matrix)[0][1]*100\n",
        "matchpercent = round(matchpercent,2)\n",
        "\n",
        "print(\"Your Resume matches about \" + str(matchpercent) + \"% of the job\")"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Similarity Score: \n",
            "[[1.         0.51460293]\n",
            " [0.51460293 1.        ]]\n",
            "Your Resume matches about 51.46% of the job\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MheyHWX92P56"
      },
      "source": [
        "#all custom keywords should be in lower case\n",
        "def find_score(jobdes,filename,setKeywords,customKeywords,df):   \n",
        "    resume=Preprocessfile(filename)\n",
        "    customKeywords = ' '.join(customKeywords)\n",
        "    jobdes=jobdes + ' ' + customKeywords\n",
        "    text=[resume,jobdes]\n",
        "    cv = CountVectorizer()\n",
        "    count_matrix = cv.fit_transform(text)\n",
        "    print(cosine_similarity(count_matrix))\n",
        "    matchpercent = cosine_similarity(count_matrix)[0][1]*100\n",
        "    matchpercent = round(matchpercent,2)\n",
        "    print(matchpercent)\n",
        "    length=len(setKeywords)  #need to add more keywords and improve model\n",
        "    Dict={\n",
        "        'Data Science':'datascience',\n",
        "        'Machine Learning':'machinelearning',\n",
        "        'Web Development':'webdev',\n",
        "        'Human resources':'hr',\n",
        "        'App Development':'appdev'\n",
        "    }\n",
        "    keyword=[]\n",
        "    for i in range(0,length):\n",
        "      keyword.append([nlp(resume) for resume in df[Dict[setKeywords[i]]].dropna(axis = 0)])\n",
        "    matcher = PhraseMatcher(nlp.vocab)\n",
        "    for i in range(0,length) :\n",
        "      matcher.add(Dict[setKeywords[i]],None,*keyword[i])\n",
        "    doc = nlp(resume)\n",
        "    matches = matcher(doc)\n",
        "    print(matches)\n",
        "    #The following is not required but additional data of the score can be obtained with the dataframe\n",
        "    KEYS = []\n",
        "    WORDS= []\n",
        "    for match_id, start, end in matches:\n",
        "        keys = nlp.vocab.strings[match_id]  \n",
        "        words = doc[start : end]               \n",
        "        print(f'{keys}  {words}')\n",
        "        KEYS.append(keys);\n",
        "        WORDS.append(words);\n",
        "    DF=pd.DataFrame(KEYS,columns=['Type'])\n",
        "    DF['Keyword']=WORDS\n",
        "    print(DF)\n",
        "    result={\n",
        "        'score': matchpercent,\n",
        "        'totalmatches':len(matches)\n",
        "    }\n",
        "    for i in range(0,length) :\n",
        "      result[setKeywords[i]]=len(DF.loc[DF['Type']==Dict[setKeywords[i]]])\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwgMl1_zs48H",
        "outputId": "084617c3-40fb-4b8d-be9c-08cbff920c0a"
      },
      "source": [
        "#FLOW\n",
        "setKeywords=['Data Science','Machine Learning']\n",
        "customKeywords=['spanish','hindi','opencv']\n",
        "\n",
        "\n",
        "jobdes=Preprocessfile('jobtype.txt')  #the job description is preprocessed outside as the same job description is used for the multiple resumes\n",
        "\n",
        "df = pd.read_csv('setkeywords.csv') #all the processed similar keywords are stored in a smaller csv file instead of a .model file\n",
        "\n",
        "#iterate through all resumes here\n",
        "results=find_score(jobdes,'resume.pdf',setKeywords,customKeywords,df);\n",
        "\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.51409916]\n",
            " [0.51409916 1.        ]]\n",
            "51.41\n",
            "[(14878926805768099270, 0, 1), (14878926805768099270, 17, 18), (14878926805768099270, 27, 28), (14878926805768099270, 27, 29), (14878926805768099270, 53, 54), (14878926805768099270, 53, 55), (9223223603407622304, 55, 57), (14878926805768099270, 55, 57), (14878926805768099270, 58, 59), (14878926805768099270, 60, 61), (14878926805768099270, 60, 62), (9223223603407622304, 62, 64), (14878926805768099270, 62, 64), (9223223603407622304, 64, 65), (14878926805768099270, 64, 65), (14878926805768099270, 65, 66), (9223223603407622304, 66, 67), (14878926805768099270, 66, 67), (14878926805768099270, 76, 77), (14878926805768099270, 148, 149), (14878926805768099270, 157, 158), (9223223603407622304, 159, 161), (14878926805768099270, 159, 161), (14878926805768099270, 175, 176), (14878926805768099270, 190, 191), (14878926805768099270, 192, 193), (14878926805768099270, 192, 194), (9223223603407622304, 195, 196), (14878926805768099270, 195, 196), (14878926805768099270, 197, 198)]\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data analysis\n",
            "datascience  data\n",
            "datascience  data analysis\n",
            "machinelearning  machine learning\n",
            "datascience  machine learning\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data analysis\n",
            "machinelearning  machine learning\n",
            "datascience  machine learning\n",
            "machinelearning  python\n",
            "datascience  python\n",
            "datascience  r\n",
            "machinelearning  matlab\n",
            "datascience  matlab\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data\n",
            "machinelearning  machine learning\n",
            "datascience  machine learning\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data\n",
            "datascience  data analysis\n",
            "machinelearning  python\n",
            "datascience  python\n",
            "datascience  r\n",
            "               Type              Keyword\n",
            "0       datascience               (data)\n",
            "1       datascience               (data)\n",
            "2       datascience               (data)\n",
            "3       datascience     (data, analysis)\n",
            "4       datascience               (data)\n",
            "5       datascience     (data, analysis)\n",
            "6   machinelearning  (machine, learning)\n",
            "7       datascience  (machine, learning)\n",
            "8       datascience               (data)\n",
            "9       datascience               (data)\n",
            "10      datascience     (data, analysis)\n",
            "11  machinelearning  (machine, learning)\n",
            "12      datascience  (machine, learning)\n",
            "13  machinelearning             (python)\n",
            "14      datascience             (python)\n",
            "15      datascience                  (r)\n",
            "16  machinelearning             (matlab)\n",
            "17      datascience             (matlab)\n",
            "18      datascience               (data)\n",
            "19      datascience               (data)\n",
            "20      datascience               (data)\n",
            "21  machinelearning  (machine, learning)\n",
            "22      datascience  (machine, learning)\n",
            "23      datascience               (data)\n",
            "24      datascience               (data)\n",
            "25      datascience               (data)\n",
            "26      datascience     (data, analysis)\n",
            "27  machinelearning             (python)\n",
            "28      datascience             (python)\n",
            "29      datascience                  (r)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao-R9-t2_ZRO",
        "outputId": "be20635f-1773-4fa2-92d8-4d0cc7524150"
      },
      "source": [
        "results #each number of matches is returned."
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Data Science': 24, 'Machine Learning': 6, 'score': 51.41, 'totalmatches': 30}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZM_fIInFC9B"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}